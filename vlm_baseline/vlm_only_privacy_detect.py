# python vlm_only_privacy_detect.py --start 0 --end 440 --context_type Breach
# python vlm_only_privacy_detect.py --start 0 --end 440 --context_type NoBreach


import os
import json
import pandas as pd
from PIL import Image
import torch
from transformers import AutoProcessor, LlavaProcessor, LlavaForConditionalGeneration
from tqdm import tqdm

# åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨
model_name = "llava-hf/llava-1.5-13b-hf"
vlm_model = LlavaForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True
).to("cuda")
vlm_processor = LlavaProcessor.from_pretrained(model_name)

# é…ç½®è·¯å¾„å‚æ•°
image_dir = "input/images/input_images"
context_paths = {
    "Breach": "input/context_behavior/context_privacy.json",
    "NoBreach": "input/context_behavior/context_nonprivacy.json"
}
excel_path = "output/experiments.xlsx"


# åŠ è½½ä¸Šä¸‹æ–‡æ•°æ®
def load_context_data(context_type):
    with open(context_paths[context_type], "r") as f:
        data = json.load(f)
        return {item["image_ID"]: item["context"] for item in data}

# æ¨ç†å‡½æ•°
def run_vlm_inference(image_path, context):
    image = Image.open(image_path).convert("RGB")
    
    # ä»¥â€œé—®é¢˜â€æ–¹å¼æé—®ï¼ˆæ¨¡å‹æœ€ä¹ æƒ¯çš„å½¢å¼ï¼‰
    question = (
        f"Does this image, considering the following context â€” "
        f"'{context}' â€” contain any element that may cause a privacy breach? "
        f"Reply begin with YES or NO, and briefly explain why."
        # f""Reply in the format: 'YES â€” reason' or 'NO â€” reason'.\n""
    )
    input_text = f"Question: <image>\n{question}\nAnswer:"
    
    inputs = vlm_processor(text=input_text, images=image, return_tensors="pt").to("cuda")
    output_ids = vlm_model.generate(**inputs, max_new_tokens=30)
    # output_ids = vlm_model.generate(
    # **inputs,
    # max_new_tokens=30,          # â¬…ï¸ å¢å¤§ token è¾“å‡ºé™åˆ¶
    # do_sample=True,             # â¬…ï¸ å¯ç”¨é‡‡æ ·
    # temperature=1,            # â¬…ï¸ ä¿æŒç¨³å®šè¾“å‡ºï¼ŒåŒæ—¶ä¸å¤±å»å¤šæ ·æ€§
    # top_p=0.9                   # â¬…ï¸ é™åˆ¶é›†ä¸­ç”Ÿæˆï¼Œæå‡è´¨é‡
    # )

    response = vlm_processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()
    return response



# æ‰¹é‡æ‰§è¡Œå‡½æ•°
def run_batch_vlm(start_row, end_row, context_type):
    df = pd.read_excel(excel_path)
    context_data = load_context_data(context_type)

    for i in range(start_row, end_row + 1):
        row = df.iloc[i]
        id_val = str(row["ID"])
        context = context_data.get(id_val)
        image_path = os.path.join(image_dir, f"{id_val}.jpg")

        result_col = f"Model Result_{context_type}"
        interp_col = f"Model Results Interpretation_{context_type}"

        # âœ… æ‰“å°å½“å‰å¤„ç†ä¿¡æ¯
        print(f"\nğŸ” Processing ID: {id_val}  ({i - start_row + 1}/{end_row - start_row + 1})")
        print(f"ğŸ“ Context: {context}\n")

        # âœ… æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆæ‰¾ä¸åˆ° context æ—¶ï¼‰
        if not context:
            print(f"âš ï¸ Context not found for ID: '{id_val}'")
        if not os.path.exists(image_path):
            print(f"âš ï¸ Image not found: '{image_path}'")

        if not context or not os.path.exists(image_path):
            df.at[i, result_col] = "Missing Input"
            df.to_excel(excel_path, index=False)
            continue

        try:
            result = run_vlm_inference(image_path, context)
            print(f"ğŸ¤– VLM Output: {result}")

            # æå– "Answer:" ä¹‹åçš„éƒ¨åˆ†
            if "Answer:" in result:
                answer_part = result.split("Answer:")[-1].strip()
                if answer_part:
                    determination = answer_part.split()[0].strip().upper()
                    interpretation = answer_part[len(determination):].strip()
                    df.at[i, result_col] = determination
                    df.at[i, interp_col] = interpretation
                else:
                    df.at[i, result_col] = "Unclear"
                    df.at[i, interp_col] = ""
            else:
                df.at[i, result_col] = "Unclear"
                df.at[i, interp_col] = result

        except Exception as e:
            df.at[i, result_col] = "ERROR"
            df.at[i, interp_col] = str(e)

        df.to_excel(excel_path, index=False)



# å‘½ä»¤è¡Œè°ƒç”¨å…¥å£
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--start", type=int, required=True, help="èµ·å§‹è¡Œå·")
    parser.add_argument("--end", type=int, required=True, help="ç»ˆæ­¢è¡Œå·")
    parser.add_argument("--context_type", type=str, required=True, choices=["Breach", "NoBreach"],
                        help="é€‰æ‹©ä¸Šä¸‹æ–‡ç±»å‹: 'Breach' æˆ– 'NoBreach'")
    args = parser.parse_args()

    run_batch_vlm(args.start, args.end, args.context_type)
